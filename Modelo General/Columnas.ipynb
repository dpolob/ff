{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lista_train: ['./train\\\\ch2465_A462A.csv', './train\\\\ch2809_A522A.csv', './train\\\\ch2810_A540A.csv', './train\\\\ch63_A505A.csv', './train\\\\ch88_A461A.csv']\n",
      "lista_forecast: ['./forecast\\\\ch76_A353A.csv']\n",
      "Altitud estacion forecast: 353\n",
      "Altitud estacion: 462\n",
      "Estacion: ./train\\ch2465_A462A.csv, tamaño dataset antes: (0, 133)\n",
      "Estacion: ./train\\ch2465_A462A.csv, tamaño dataset despues: (8664, 133)\n",
      "Altitud estacion: 522\n",
      "Estacion: ./train\\ch2809_A522A.csv, tamaño dataset antes: (8664, 133)\n",
      "Estacion: ./train\\ch2809_A522A.csv, tamaño dataset despues: (17328, 133)\n",
      "Altitud estacion: 540\n",
      "Estacion: ./train\\ch2810_A540A.csv, tamaño dataset antes: (17328, 133)\n",
      "Estacion: ./train\\ch2810_A540A.csv, tamaño dataset despues: (25992, 133)\n",
      "Altitud estacion: 505\n",
      "Estacion: ./train\\ch63_A505A.csv, tamaño dataset antes: (25992, 133)\n",
      "Estacion: ./train\\ch63_A505A.csv, tamaño dataset despues: (34656, 133)\n",
      "Altitud estacion: 461\n",
      "Estacion: ./train\\ch88_A461A.csv, tamaño dataset antes: (34656, 133)\n",
      "Estacion: ./train\\ch88_A461A.csv, tamaño dataset despues: (43320, 133)\n"
     ]
    }
   ],
   "source": [
    "#PASADO:      TempP0, TempP1, ..., TempP70, TempP71            (nx72)\n",
    "#FUTURO:      TempF71, TempF72,..., TempF95                    (nx24)\n",
    "#ALTITUD:     Altitud_Estacion - Altitud_Estacion_Prediccion   (nx1)\n",
    "#MES:         Onehot encoding mes del año                      (nx12)\n",
    "#REAL:        TempP71, TempP72,..., TempP95                    (nx24)\n",
    "\n",
    "\n",
    "\n",
    "def crear_dataset(df_pasado, df_forecast, altitud_estacion, altitud_forecast):\n",
    "    matriz_pasado = crear_pasado(df_pasado)\n",
    "    assert len(df_pasado) == len(df_forecast),'La longitud de los dataset de train y forecast no coinciden{} - {}'.format(len(df_pasado), len(df_forecast))\n",
    "    matriz_futuro = crear_futuro(df_forecast)\n",
    "    matriz_altitud = np.repeat(altitud_estacion - altitud_forecast, len(df_train) - 96).reshape(-1,1)\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    matriz_mes = lb.transform(np.array(df_forecast['fecha'].dt.month.values)[96:])\n",
    "    matriz_real = crear_real(df_train)\n",
    "    #concatenar matrices\n",
    "    return np.concatenate((matriz_pasado,matriz_futuro,matriz_altitud, matriz_mes, matriz_real), axis=1)\n",
    "    \n",
    "def crear_pasado(df_pasado):\n",
    "    matriz_pasado = np.empty((len(df_pasado) - 72 - 24, 72)) # matriz vacia de len(df) x 72 \n",
    "    for i in range(0, len(df_pasado) - 72 - 24):\n",
    "        for j in range(0, 72):\n",
    "            matriz_pasado[i, j] = df_pasado.iloc[i + j, 2] # coger columna 2 que es temperatura\n",
    "    return matriz_pasado\n",
    "\n",
    "def crear_futuro(df_forecast):\n",
    "    matriz_futuro = np.empty((len(df_forecast) - 72 - 24, 24)) # matriz vacia de len(df) x 24\n",
    "    for i in range(72, len(df_forecast) - 24):\n",
    "        for j in range(0, 24):\n",
    "            matriz_futuro[i-72, j] = df_forecast.iloc[i + j, 2] # coger columna 2 que es temperatura\n",
    "    return matriz_futuro\n",
    "\n",
    "def crear_real(df_train):\n",
    "    matriz_real = np.empty((len(df_train) - 72 - 24, 24)) # matriz vacia de len(df) x 24\n",
    "    for i in range(72, len(df_train) - 24):\n",
    "        for j in range(0, 24):\n",
    "            matriz_real[i-72, j] = df_train.iloc[i + j, 2] # coger columna 2 que es temperatura\n",
    "    return matriz_real\n",
    "\n",
    "\n",
    "lista_train = glob.glob(\"./train/ch*.csv\")\n",
    "print(\"lista_train: {}\".format(lista_train))\n",
    "lista_forecast = glob.glob(\"./forecast/ch*.csv\")\n",
    "print(\"lista_forecast: {}\".format(lista_forecast))\n",
    "\n",
    "headers = ['fecha', 'id', 'temp']\n",
    "dtypes = {'fecha': 'str', 'id': 'float', 'temp': 'float'}\n",
    "parse_dates = ['fecha']\n",
    "\n",
    "df_forecast = pd.DataFrame()\n",
    "for f in lista_forecast:\n",
    "    df_forecast = pd.concat([df_forecast, pd.read_csv(f, decimal=\".\", sep=\",\", header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)])\n",
    "    altitud_forecast = int(f.split('A')[1])\n",
    "    print(\"Altitud estacion forecast: {}\".format(altitud_forecast))\n",
    "\n",
    "train = np.empty((0,133))\n",
    "for f in lista_train:\n",
    "    df_train = pd.DataFrame() # Vaciar dataframe\n",
    "    df_train = pd.read_csv(f, decimal=\".\", sep=\",\", header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)\n",
    "    altitud_estacion = int(f.split('A')[1])\n",
    "    print(\"Altitud estacion: {}\".format(altitud_estacion))\n",
    "    datos_estacion = crear_dataset(df_train, df_forecast, altitud_estacion, altitud_forecast)\n",
    "    #adjuntar matrices\n",
    "    \n",
    "    print(\"Estacion: {}, tamaño dataset antes: {}\".format(f, train.shape))\n",
    "    train = np.append(train, datos_estacion, axis=0)\n",
    "    print(\"Estacion: {}, tamaño dataset despues: {}\".format(f, train.shape))\n",
    "\n",
    "#Normalizar columna de temperatura\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "temp_scaler = pickle.load(open('./mmscaler.pickle', 'rb'))\n",
    "print(temp_scaler)\n",
    "train[:, :96] = temp_scaler.transform(train[:, :96])\n",
    "train[:, 108:132] = temp_scaler.transform(train[:, 108:132])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43320, 1)\n"
     ]
    }
   ],
   "source": [
    "train=train2\n",
    "alt_scaler = MinMaxScaler()\n",
    "train[:, 96] = alt_scaler.fit_transform(train[:, 96].reshape(-1,1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569620253164558\n"
     ]
    }
   ],
   "source": [
    "print(train2[33000,96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50408759 0.49436381 0.49004214 ... 0.57539525 0.54784456 0.53055786]\n",
      " [0.49436381 0.49004214 0.48085857 ... 0.54784456 0.53055786 0.51867325]\n",
      " [0.49004214 0.48085857 0.45168725 ... 0.53055786 0.51867325 0.51002989]\n",
      " ...\n",
      " [0.55396694 0.53689632 0.50650052 ... 0.52119422 0.51363129 0.4796341 ]\n",
      " [0.53689632 0.50650052 0.4788778  ... 0.51363129 0.4796341  0.46760543]\n",
      " [0.50650052 0.4788778  0.4623834  ... 0.4796341  0.46760543 0.46245543]]\n"
     ]
    }
   ],
   "source": [
    "print(train[:,:72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crear_muestras(df):\n",
    "    \"\"\"\n",
    "    devuelve una matriz de la forma:\n",
    "    Temp0, Temp1,..., Temp19, Temp20\n",
    "    Temp1, Temp2,..., Temp20, Temp21\n",
    "    \n",
    "    Input: pandas dataframe\n",
    "    Output: numpy\n",
    "    \"\"\"\n",
    "    dato = np.empty((len(df) - 19, 20))\n",
    "    for i in range(0, len(df) - 19):\n",
    "        for j in range(0, 20):\n",
    "            dato[i, j] = df.iloc[i + j, 1]\n",
    "    \n",
    "    return dato\n",
    "\n",
    "# variables categoricas: utilizar la estacion del año\n",
    "df['estacion'] = df['fecha'].dt.month.apply(lambda x: 'primavera' if x >= 3 and x < 6 \n",
    "                                                 else 'verano' if x >=6 and x < 9\n",
    "                                                 else 'otoño' if x >= 9 and x < 12\n",
    "                                                 else 'invierno')\n",
    "\n",
    "# montar el dataset\n",
    "df = pd.concat( [df.loc[0:len(df)-20], pd.DataFrame(crear_muestras(df))], axis=1)\n",
    "print(\"=========CABECERA===========\\n\", df.head())\n",
    "print(\"===========COLA=============\\n\", df.tail())\n",
    "\n",
    "df = df.drop(['fecha', 'temp'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
